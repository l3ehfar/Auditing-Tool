<script lang="ts">
  import { goto } from '$app/navigation';
  import { onMount } from 'svelte';
  import { setProgress } from '$lib/marcelle/logging';
  import { notification } from '@marcellejs/core';
  import type { User } from '$lib/marcelle';
  import { base } from '$app/paths';
  import { checkAndRedirect } from '$lib/redirections';
  import { pageProgress } from '$lib/marcelle/progress';

  export let data: { user: User | null };
  let answers = {
    biasCheck: '',
    taskCheck: '',
  };

  let attempts = 0;

  $: pageProgress.set(
    (answers.biasCheck && answers.taskCheck ? 100 : 0)
  );
  $: canSubmit = $pageProgress === 100;

  onMount(async () => {
    await checkAndRedirect(data.user, 'task-description');
    setProgress('task-description');
  });

  function recordAnswer(type: 'biasCheck' | 'taskCheck', value: string) {
    answers[type] = value;
  }

  function submit() {
    const biasCorrect = answers.biasCheck === 'd';
    const taskCorrect = answers.taskCheck === 'c';

    if (biasCorrect && taskCorrect) {
      goto(`${base}/pre-questionnaire`);
      return;
    }

    if (!biasCorrect && !taskCorrect) {
      goto(`${base}/returnSubmission`);
      return;
    }

    if (attempts === 0) {
      attempts += 1;
      notification({
        title: 'Try Again',
        message: 'One or more answers are incorrect. Please review the instructions and try again. Be aware you have one more try.',
        type: 'danger',
        duration: 6000,
      });
    } else {
      goto(`${base}/returnSubmission`);
    }
  }
</script>

  <div class="mx-auto w-full max-w-3xl">
    <div class="bg-white shadow-lg rounded-lg p-8">
      <h1 class="text-3xl font-bold text-center">Information Sheet and Consent Form</h1>
      <p class="text-lg text-center">Please read this information document carefully.</p>

      <section class="mt-6">
        <h2 class="text-xl font-semibold">What is Gender Bias in Image Captioning?</h2>
        <p>
          Gender bias in image captioning models refers to situations where the model produces captions that reflect or reinforce 
          harmful gender stereotypes, assumptions, or unequal treatment based on gender.
        </p>
      
        <p class="mt-4">In the context of job-related image captions, this might include:</p>
        <ul class="list-disc list-inside mt-2">
          <li>Assigning certain roles or professions only to a specific gender,</li>
          <li>Describing people differently depending on their perceived gender,</li>
          <li>Using gendered language unnecessarily when gender is irrelevant to the task,</li>
          <li>...and other forms of biased associations or descriptions.</li>
        </ul>

      </section>

      <section class="mt-6">
        <h2 class="text-xl font-semibold">Comprehension Check</h2>
        <p class="mt-2 font-medium">What does gender bias mean in the context of image captioning model?</p>
      
        <form class="mt-4 space-y-2">
          <label class="block">
            <input type="radio" name="bias-check" value="c" on:change={() => recordAnswer('biasCheck', 'a')} class="mr-2">
            A. The model always describes people in a positive way.
          </label>
      
          <label class="block">
            <input type="radio" name="bias-check" value="c" on:change={() => recordAnswer('biasCheck', 'b')} class="mr-2">
            B. The model uses the same caption for every image.
          </label>
      
          <label class="block">
            <input type="radio" name="bias-check" value="c" on:change={() => recordAnswer('biasCheck', 'c')} class="mr-2">
            C. The model sometimes makes spelling mistakes.
          </label>
      
          <label class="block">
            <input type="radio" name="bias-check" value="c" on:change={() => recordAnswer('biasCheck', 'd')} class="mr-2">
            D. The model describes people differently based on their gender, even when it’s not relevant.
          </label>
      
        </form>
      </section>
      
      <section class="mt-6">
        <h2 class="text-xl font-semibold">Your Task: Auditing the Model for Bias</h2>
        
        <p class="mt-4">
          You will explore how an image captioning model describes people in various job settings.
        </p>
      
        <p class="mt-2">
          Your goal is <strong>not</strong> to label or classify images, but to <strong>identify patterns of gender bias in the captions </strong> generated by the model.
        </p>
      
        <p class="mt-2">
          You'll use an interface that lets you:
        </p>
      
        <ul class="list-disc list-inside mt-2">
          <li>Explore an image dataset</li>
          <li>See the model's generated caption for each image</li>
          <li>Use “Bias Cards” to document observed biases in the captions</li>
        </ul>
      
        <p class="mt-4">
          Each Bias Card includes:
        </p>
        <ul class="list-disc list-inside mt-2">
          <li>A textual explanation of the gender bias in the model's captions (e.g., what you observe, when this bias occurs, etc.)</li>
          <li>A set of supporting images (drag-and-drop from the dataset) that illustrate the issue</li>
        </ul>
      
        <p class="mt-4">
          Think of yourself as an <strong>auditor or investigator</strong> looking for <strong>systemic biases</strong> — not just annotating individual images.
        </p>
      
        <p class="mt-2">
          Your objective is to provide a <strong>comprehensive overview</strong> of the model’s gender bias, explain when it occurs and how elements in the images may contribute to it.
        </p>

        <p class="mt-2">
          Please make sure to complete the task as described. If anything is unclear, feel free to contact the researchers.
        </p>
      </section>

      <section class="mt-6">
        <h2 class="text-xl font-semibold">Comprehension Check</h2>
        <p class="mt-2 font-medium">What is your main task in this study?</p>
      
        <form class="mt-4 space-y-2">
          <label class="block">
            <input type="radio" name="task-check" value="c" on:change={() => recordAnswer('taskCheck', 'a')} class="mr-2">
            A. Classify each person in the image by their job and gender.
          </label>
      
          <label class="block">
            <input type="radio" name="task-check" value="c" on:change={() => recordAnswer('taskCheck', 'b')} class="mr-2">
            B. Annotate images based on the job occupations.
          </label>
      
          <label class="block">
            <input type="radio" name="task-check" value="c" on:change={() => recordAnswer('taskCheck', 'c')} class="mr-2">
            C. Identify and describe patterns of gender bias in the model's captions.
          </label>
      
          <label class="block">
            <input type="radio" name="task-check" value="c" on:change={() => recordAnswer('taskCheck', 'd')} class="mr-2">
            D. Improve the captions by correcting grammar and spelling mistakes.
          </label>
        </form>
      </section>
      
      
  
      <div class="text-center my-6">
          <button class="btn btn-primary mt-4" on:click={submit} disabled={!canSubmit}>Continue</button>
        </div>
  
    </div>
  </div>
  
  <style>
    ul {
      margin-bottom: 12px;
    }
  </style>
  